{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nFQLKQ6hfXch"},"outputs":[],"source":["# Installing Google Generative API (silenced output and upgrade)\n","%pip install -q -U google-generativeai\n","\n","# Import the generative AI library\n","import google.generativeai as genai\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37j_DsoCFIPI"},"outputs":[],"source":["# Configurações iniciais (Initial Configuration in Portuguese)\n","import google.generativeai as genai\n","\n","# Define your Google Cloud API key and store it securely (**WARNING: This is an example key, replace it with your own!**) https://aistudio.google.com/app/apikey\n","GOOGLE_API_KEY = \"\"\n","\n","# Configure the Google GenerativeAI library with your API key\n","genai.configure(api_key=GOOGLE_API_KEY)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g78B52KqFKEB"},"outputs":[],"source":["# List available models that support content generation\n","for model in genai.list_models():\n","  if 'generateContent' in model.supported_generation_methods:\n","    print(model.name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpTrYZVhFMBk"},"outputs":[],"source":["generation_config = {\n","  \"candidate_count\": 1,  # Number of text generation attempts to produce\n","  \"temperature\": 0.5,   # Controls randomness/creativity of generated text\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5gRBthJFNtD"},"outputs":[],"source":["safety_settings = {\n","    'HATE': 'BLOCK_NONE',  # Disable hate speech filtering\n","    'HARASSMENT': 'BLOCK_NONE',  # Disable harassment filtering\n","    'SEXUAL': 'BLOCK_NONE',  # Disable sexually suggestive content filtering\n","    'DANGEROUS': 'BLOCK_NONE',  # Disable dangerous or harmful content filtering\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLZiMTt9FPiT"},"outputs":[],"source":["# Create a generative model object with specified name, configuration, and safety settings\n","model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n","                              generation_config=generation_config,\n","                              safety_settings=safety_settings)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smMXqoQdFbBS"},"outputs":[],"source":["# Send a prompt (starting point) to the model for text generation\n","prompt = \"you can make an a request to Gemini right here\"\n","response = model.generate_content(prompt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bn_SHb-NFRuW"},"outputs":[],"source":["# Initiate a chat session with the model (empty history for a fresh conversation)\n","chat = model.start_chat(history=[])\n","\n","while True:\n","  # Get user input as the prompt for the model\n","  prompt = input('waiting prompt (Type \"end\" to quit): ')\n","\n","  # Exit the loop if the user enters \"end\" \n","  if prompt == \"fim\":\n","    break\n","\n","  # Send the prompt to the model and retrieve the response\n","  response = chat.send_message(prompt)\n","\n","  # Print the model's response\n","  print(\"answer:\", response.text, '\\n\\n')\n","\n","# Chat session ends after the loop exits\n","print(\"chat ended.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ar8Csf_QFT0n"},"outputs":[],"source":["# Calls chat variables\n","chat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acOFbPChFf4L"},"outputs":[],"source":["# show chat history\n","chat.history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgRLlYkVFiLg"},"outputs":[],"source":["# Import libraries for formatting and displaying text (potentially for a Jupyter Notebook environment)\n","import textwrap\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","def to_markdown(text):\n","  \"\"\"Converts plain text to Markdown format with indentation and bullet points.\n","\n","  Args:\n","      text: The plain text string to be converted.\n","\n","  Returns:\n","      A Markdown object representing the formatted text.\n","  \"\"\"\n","\n","  # Replace bullet point symbol (•) with a standard Markdown bullet point (*).\n","  text = text.replace('•', '  *')\n","\n","  # Indent the entire text block using textwrap.indent with a custom predicate\n","  #   to ensure all lines are indented ('> ' as prefix).\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n","\n","# Iterate through the chat history retrieved from the model\n","for message in chat.history:\n","  # Convert the message text to Markdown format with styling and indentation\n","  formatted_message = to_markdown(f'**{message.role}**: {message.parts[0].text}')\n","\n","  # Display the formatted message using IPython.display (likely for a Jupyter Notebook)\n","  display(formatted_message)\n","\n","  # Print a separator line for readability\n","  print('-------------------------------------------')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import PIL.Image  # Import the Python Imaging Library (PIL) for image operations\n","\n","# Specify the path to the image file (replace 'brain.jpeg' with your actual filename)\n","image_path = './img/brain.jpeg'\n","\n","# Open the image file using PIL.Image.open()\n","try:\n","  image = PIL.Image.open(image_path)\n","  print(f\"Image '{image_path}' opened successfully.\")  # Print a success message\n","except FileNotFoundError:  # Handle the error if the file is not found\n","  print(f\"Error: Image file '{image_path}' not found.\")\n","  exit(1)  # Exit the program with an error code (1)\n","img"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# activates the gemini pro vision\n","model = genai.GenerativeModel('gemini-pro-vision')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Generates an response to the image\n","response = model.generate_content(img)\n","\n","to_markdown(response.text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#generate a response based on a image but now you can interact with it using the function generate_content\n","response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n","response.resolve()\n","\n","to_markdown(response.text)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNPk1ZtlkIaXQAWBM2bytD4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
